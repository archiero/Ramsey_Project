{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8461.877248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[math.factorial()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(40,3)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847670407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76289.506794"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def choose(n,k):\n",
    "    return int(math.factorial(n)/math.factorial(k)/math.factorial(n-k))\n",
    "\n",
    "n = 40\n",
    "num_cliques = choose(n,10) + choose(n,3)\n",
    "print(num_cliques)\n",
    "num_streams = 24\n",
    "threads_per_stream = 2**31/num_streams\n",
    "num_cliques/threads_per_stream\n",
    "num_bytes = (choose(10,2)*choose(n,10) + choose(3,2)*choose(n,3))*2\n",
    "num_bytes/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accomplished in this update:\n",
    "1. Change shared so it isn't hard-coded \n",
    "1. Add some limits on the state space from the Lesser paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal for next update:\n",
    "1. Get threads checking multiple sub-graphs\n",
    "1. Get Streams running on PyCUDA to allow multiple simultaneous searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note to Dr. Cook:\n",
    "I have spent many hours trying to get shared more convenient to code into CUDA. As of right now, the most convenient I have discovered to do shared memory is how it is done below. Long story short, the amount of shared memory allocated, as far as I can tell, can not be passed down as a variable the way that we pass down all of the other variables and arrays using PyCUDA. I believe this to be a CUDA limitation, not a PyCUDA limitation. To get around this, I have now moved the CUDA kernel call outside of the main_ramsey function to the cell block where I am actually declared the beta variable, num_steps variable and etc so that we can edit it as necessary when we are running the Markov search later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVIDIA Documentation has good examples and explanations plus helpful tips for optimization\n",
    "http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#maximize-instruction-throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMITS FOR THE DATA TYPES:\n",
    "\n",
    "int8 \tByte (-128 to 127)\n",
    "\n",
    "int16 \tInteger (-32768 to 32767)\n",
    "\n",
    "int32 \tInteger (-2147483648 to 2147483647)\n",
    "\n",
    "int64 \tInteger (-9223372036854775808 to 9223372036854775807)\n",
    "\n",
    "uint8 \tUnsigned integer (0 to 255)\n",
    "\n",
    "uint16 \tUnsigned integer (0 to 65535)\n",
    "\n",
    "uint32 \tUnsigned integer (0 to 4294967295)\n",
    "\n",
    "uint64 \tUnsigned integer (0 to 18446744073709551615)\n",
    "\n",
    "## CONVERSION USING NUMPY:\n",
    "\n",
    "(unsigned) char = numpy.(u)int8\n",
    "\n",
    "(unsigned) short = numpy.(u)int16\n",
    "\n",
    "(unsigned) int = numpy.(u)int32\n",
    "\n",
    "(unsigned) long = numpy.(u)int64 (only 64-bit)\n",
    "\n",
    "floats = numpy.float32\n",
    "\n",
    "double = numpy.float64\n",
    "\n",
    "all pointers ( e.g int *, float ***, anything at all) should be numpy.intp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a603fcf36333>, line 123)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-a603fcf36333>\"\u001b[0;36m, line \u001b[0;32m123\u001b[0m\n\u001b[0;31m    \"\"\")\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#without shared memory of coloring_GPU, 50000 steps with R(3,7) with 25 nodes took 49, 50, 52, 52 seconds\n",
    "#without shared, 50000 steps with R(3,7) and 30 nodes took 2:36\n",
    "#with shared memory of coloring_GPU, 50000 steps with R(3,7) and 30 nodes took 2:19\n",
    "#with shared memory of coloring_GPU, 50000 steps with R(3,7) with 25 took 44, 46, 47, 47,  seconds\n",
    "from setup import *\n",
    "from collections import Counter\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "Counter()\n",
    "def main_random(Ramsey, num_vertices, num_steps, beta=2):\n",
    "    start_time = datetime.datetime.now()\n",
    "    print()\n",
    "\n",
    "    def choose(n,k):\n",
    "        return int(math.factorial(n)/math.factorial(k)/math.factorial(n-k))\n",
    "    #This code is solely based on Theorem 7 from the Lesser Paper found in the Papers folder. I went ahead and added\n",
    "    #all of the extra cases purely for the sake of robustness. Also, this only covers the case of a two-coloring \n",
    "    #where the smallest clique size looking for is 3. Eventually, I will look for other cases so we could theoretically\n",
    "    #search for different Ramsey numbers. Finally, I am assuming that the color with the smallest clique size is red and\n",
    "    #the one with the largest clique size is blue.\n",
    "    def min_red_edges(Ramsey, num_vertices):\n",
    "        sorted_Ramsey = np.sort(Ramsey)\n",
    "        k = sorted_Ramsey[1]\n",
    "        if len(sorted_Ramsey) != 2 or sorted_Ramsey[0] != 3:\n",
    "            return(0)\n",
    "        elif num_vertices <=2*k:\n",
    "            return(num_vertices-k)\n",
    "        elif num_vertices <= 5*k/2:\n",
    "            return(3*num_vertices - 5*k)\n",
    "        else:\n",
    "            return(5*num_vertices - 10*k)\n",
    "    min_red = min_red_edges(Ramsey, num_vertices)\n",
    "    num_colors = len(Ramsey)\n",
    "    Colors = np.arange(num_colors)\n",
    "    Vertices = np.arange(num_vertices)\n",
    "    Edges = list(it.combinations(Vertices,2))\n",
    "    #reverse lookup for edges below.  Eg if slot 3 above contains edge (2,5), the the dict below has entry (2,5):3\n",
    "    Edges_idx = dict((edge, idx) for idx,edge in enumerate(Edges)) \n",
    "    num_edges = np.uint32(len(Edges))\n",
    "\n",
    "    threads_per_block = 1024\n",
    "    vertices_per_clique = Ramsey\n",
    "    edges_per_clique = np.array([choose(v,2) for v in vertices_per_clique])\n",
    "    cliques_per_color = np.asarray([choose(num_vertices,v) for v in vertices_per_clique])\n",
    "    blocks_per_color = np.ceil(cliques_per_color / threads_per_block).astype('uint32')\n",
    "    num_blocks = blocks_per_color.sum()\n",
    "    cliques_per_block = np.ceil(cliques_per_color / blocks_per_color).astype('uint32')\n",
    "    #The objects below tells each block which color and how many cliques/edges it will monitor.\n",
    "    #Note each vector is repetitive.  If color 0 gets 7 blocks, the first 7 entries will be the same\n",
    "    block_color = np.repeat(Colors,blocks_per_color).astype('int32')#.astype('uint8')#\n",
    "    block_num_cliques = np.repeat(cliques_per_block,blocks_per_color).astype('uint32')\n",
    "    block_edges_per_clique = np.repeat(edges_per_clique,blocks_per_color).astype('uint32')#.astype('uint8')#\n",
    "    \n",
    "    #The object below assigns each block to a list of cliques.  For simplicity while\n",
    "    #we construct a single matrix with a lot of unused entries.\n",
    "    #For example, edges_per_clique is different for blocks monitoring different colors.\n",
    "    #We could make a more complex structure that handles this (see old stable version)\n",
    "    #but that makes it harder to pass to the GPU.  Instead, we simply fill all \"invalid\"\n",
    "    #unused entries with the placeholder \"num_edges\", which is 1 more the the largest\n",
    "    #legal edge_idx (because Python indexes [0,1,2,...,num_edges-1]).\n",
    "    #When we color later, we color these slots with the placeholder num_colors.\n",
    "    assign_Blocks_to_Cliques = np.full([num_blocks,cliques_per_block.max(),edges_per_clique.max()],\n",
    "                                       fill_value=num_edges, dtype='uint32')\n",
    "\n",
    "    #Counters that that tracks the next open block and thread on each block\n",
    "    next_open_block = 0    \n",
    "    next_open_thread = np.zeros(num_blocks,dtype='int')\n",
    "    for color, clique_size in enumerate(Ramsey):\n",
    "        #Creates a generator to produce all cliques (the list of vertices).\n",
    "        Cliques = it.combinations(Vertices,clique_size)\n",
    "\n",
    "        #Makes the vector [0,1,2,...,num_blocks-1,0,1,2,...,num_blocks-1,....] of length num_cliques\n",
    "        assign_Cliques_to_Blocks = np.arange(cliques_per_color[color]) % blocks_per_color[color]\n",
    "        #randomizes assignment, but maintains clique counts\n",
    "        np.random.shuffle(assign_Cliques_to_Blocks)\n",
    "        #Starts at next open block\n",
    "        assign_Cliques_to_Blocks += next_open_block\n",
    "        \n",
    "        for clique_Vertices, block in zip(Cliques,assign_Cliques_to_Blocks):\n",
    "            #Gets the list of edges in this clique\n",
    "            clique_Edges = list(it.combinations(clique_Vertices,2))\n",
    "            #Converts it to edge_idx\n",
    "            clique_Edges_idx = [Edges_idx[edge] for edge in clique_Edges]\n",
    "            #Writes it to the correct block and next open thread on that block#\n",
    "            assign_Blocks_to_Cliques[block,next_open_thread[block],:edges_per_clique[color]] = clique_Edges_idx            \n",
    "            next_open_thread[block] += 1\n",
    "        next_open_block += blocks_per_color[color]\n",
    "\n",
    "#     print(\"Ramsey\");print(Ramsey);print(\"edges per clique\");print(edges_per_clique);print(\"cliques per color\");print(cliques_per_color);print(\"blocks per color\");print(blocks_per_color);print(\"cliques per block\");print(cliques_per_block)\n",
    "#     for (idx, block)  in enumerate(assign_Blocks_to_Cliques):\n",
    "#         print()\n",
    "#         print(\"block = \"+str(idx));\n",
    "#         print(\"color = \"+str(block_color[idx]));\n",
    "#         print(\"num_cliques = \"+str(block_num_cliques[idx]));\n",
    "#         print(\"edges per clique = \"+str(block_edges_per_clique[idx]));\n",
    "#         print(block.shape, block.dtype);\n",
    "#         display(block);\n",
    "#         display(compare)\n",
    "  \n",
    "    kernel_code =\"\"\"\n",
    "    #include <stdio.h>\n",
    "       __global__ void find_problems(int *block_color, int *edges_per_clique, int *edges, int *coloring, int *Problems, int edges_per_thread)\n",
    "    {\n",
    "        //const int shared_size = 435;\n",
    "        __shared__ int shared_coloring[shared_size];\n",
    "        int color = block_color[blockIdx.x];\n",
    "        int clique_idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "        if(threadIdx.x < shared_size)\n",
    "        {\n",
    "            shared_coloring[threadIdx.x] = coloring[threadIdx.x];\n",
    "        }\n",
    "        int start = clique_idx*edges_per_thread;\n",
    "        int end = start + edges_per_clique[blockIdx.x];\n",
    "        int e = start;\n",
    "        while((e < end) && (shared_coloring[edges[e]] == color))\n",
    "        {\n",
    "            e++;\n",
    "        }\n",
    "        Problems[clique_idx] = (e >= end) ? 1 : 0;\n",
    "    }\n",
    "    \"\"\")\n",
    "    \n",
    "    regex_fixing_dictionary = {\"shared_size\":num_edges}\n",
    "\n",
    "    for key, val in regex_fixing_dictionary.items():\n",
    "        kernel_code = kernel_code.replace(str(key),str(val))\n",
    "    \n",
    "    mod = SourceModule(kernel_code);\n",
    "    func = mod.get_function(\"find_problems\")\n",
    "    \n",
    "    #Code below sets up the GPU checker\n",
    "    block_color_gpu = gpuarray.to_gpu(np.array(block_color))\n",
    "    #block_num_cliques = gpuarray.to_gpu(block_num_cliques)        \n",
    "    block_edges_per_clique_gpu = gpuarray.to_gpu(block_edges_per_clique)\n",
    "    assign_Blocks_to_Cliques_gpu = gpuarray.to_gpu(assign_Blocks_to_Cliques)\n",
    "    \n",
    "    G, B, edges_per_thread = assign_Blocks_to_Cliques_gpu.shape\n",
    "    edges_per_thread = np.uint32(edges_per_thread) \n",
    "    print(\"#blocks = gridDim.x = %d, cliques per block = threads per block = blockDim.x = %d, edges per thread = %d\"%(G,B,edges_per_thread))\n",
    "    print(G, B, edges_per_thread)\n",
    "    func = mod.get_function(\"find_problems\")\n",
    "    def find_problems_cuda(coloring_gpu, coloring_cpu, printout=False, get_from_gpu=False):\n",
    "        #Recall that red is defined to be the smallest of the colors so this code checks to see if there is less\n",
    "        #red edges than allowable. If there is, then we know it can't be a good graph so there is no need to check it\n",
    "        #therefore, it is assigned the maximum amount of problems possible so that, while it technically possible to\n",
    "        #move there, it is the least likely possibility.\n",
    "        red = np.argmin(Ramsey)\n",
    "        if Counter(coloring_cpu)[red] < min_red_edges:\n",
    "            return(np.sum(cliques_per_color))\n",
    "        func(block_color_gpu, block_edges_per_clique_gpu, assign_Blocks_to_Cliques_gpu, coloring_gpu, Problems_gpu, edges_per_thread, np.int32(num_vertices), block=(threads_per_block,1,1), grid=(G,1))\n",
    "        if printout == True:\n",
    "            get_from_gpu = True\n",
    "        if get_from_gpu == True:\n",
    "            print(\"getting from gpu\")\n",
    "            Problems_cpu = Problems_gpu.get()\n",
    "            if printout == True:\n",
    "                print_problems(Problems_cpu)\n",
    "        else:\n",
    "            Problems_cpu = []\n",
    "        return gpuarray.sum(Problems_gpu).get().astype('int'), Problems_cpu\n",
    "\n",
    "    \n",
    "    #The code below setups the serial version of this algorithm in pandas on the CPU.\n",
    "    #It is much slower than the gpu version, but can be used in the absence of a GPU\n",
    "    #and to verify that the algorithms give the same answers.\n",
    "    #We msut create the \"comparison\" array.  This is a bit complicated.\n",
    "    #We will discuss 2 arrays: compare and the coloring array.\n",
    "    #First, recall that num_colors is one larger than the biggest legal color since\n",
    "    #Python indexes [0,1,...,num_colors-1]\n",
    "    #Now, fix a block and let c = block_color[block].\n",
    "    #Consider the [block, clique, edge] entry of compare.  It equals:\n",
    "    #c IF edge < num_edges_per_clique for that block\n",
    "    #num_colors IF clique >= num_edges_per_clique for that blockFalse\n",
    "    #Why?  In general there are extra rows and columns not associated to a valid edge.\n",
    "    #When we color the graph later, they are filled with num_colors.\n",
    "    #We do NOT want the \"space fillers\" to affect problem count.\n",
    "    #In the extra rows, we see [c,c,...,c,num_colors,num_colors,...,num_colors] in compare\n",
    "    #But in the coloring array, all entries will equal num_colors.\n",
    "    #Thus, it is NOT counted as a problem because the first several slots disagree.\n",
    "    #Thus, these extra rows can NEVER counts as problems cliques, as desired.\n",
    "    #Now, consider the extra columns.  All entries will equal num_colors.  This is true\n",
    "    #for BOTH compare AND the coloring array.  Thus, a row counts as a problem\n",
    "    #if and only if the first num_edges_per_clique \"valid\" entries also match.\n",
    "    #Thus the extra columns do NOT alter the \"problem status\" for valid rows, as desired.\n",
    "\n",
    "#     compare = np.full_like(assign_Blocks_to_Cliques, fill_value=num_colors)\n",
    "#     print(assign_Blocks_to_Cliques.shape)\n",
    "#     for block in range(num_blocks):\n",
    "#         compare[block,:,:block_edges_per_clique[block]] = block_color[block]\n",
    "    \n",
    "#     def find_problems_pandas(coloring, printout=False):\n",
    "#         X = coloring[assign_Blocks_to_Cliques]\n",
    "#         Y = (X == compare)\n",
    "#         Problems = np.all(Y,axis=-1)\n",
    "#         if printout == True:\n",
    "#             print_problems(Problems)\n",
    "#         return Problems.sum().astype('int'), Problems\n",
    "\n",
    "    def print_problems(Problems):        \n",
    "        Z = pd.DataFrame(Problems.astype('uint32'))\n",
    "        Z.insert(0,'problems',Z.sum(axis=1))\n",
    "        Z.insert(0,'color',block_color)\n",
    "        Z = Z.T\n",
    "        problem_idx = np.any(Z,axis=-1)\n",
    "        problem_idx[:2] = True\n",
    "        display(Z.ix[problem_idx,:])\n",
    "\n",
    "    def print_status():\n",
    "        now = datetime.datetime.now()\n",
    "        elapsed = now - start_time\n",
    "        print(\"%d steps done in %s.  Best coloring so far was step %d with %d problems.  Time now %s.\"\n",
    "                   %(step,str(elapsed).split('.')[0],step_best,num_problems_best,str(now).split('.')[0]))\n",
    "\n",
    "    \n",
    "    #Initialize the Markov chain\n",
    "    coloring_cpu = np.random.choice(Colors, size=num_edges+1, replace=True).astype('uint32')\n",
    "    coloring_cpu[num_edges] = num_colors\n",
    "    #Recall this last slot holds is a placeholder to handle \"extra\" slots.  See discussion\n",
    "    #of serial pandas algorithm above.\n",
    "    coloring_best = coloring_cpu.copy()\n",
    "    coloring_gpu = gpuarray.to_gpu(coloring_cpu.copy())\n",
    "    \n",
    "    #Problems_current = np.zeros(assign_Blocks_to_Cliques.shape[:-1]).astype('uint32')    \n",
    "    Problems_gpu = gpuarray.GPUArray(assign_Blocks_to_Cliques.shape[:-1],dtype='uint32')\n",
    "    \n",
    "\n",
    "    #num_problems_current, Problems_current = find_problems_pandas(coloring_cpu, printout=False)\n",
    "    #num_problems_current, Problems_current = find_problems_cuda(coloring_gpu, get_from_gpu=True, printout=False)\n",
    "    num_problems_current = find_problems_cuda(coloring_gpu, coloring_cpu,get_from_gpu=False, printout=False)    \n",
    "    num_problems_proposed = num_problems_current    \n",
    "    num_problems_best = num_problems_current\n",
    "    #Problems_proposed = Problems_current.copy()\n",
    "    #Problems_best = Problems_current.copy()\n",
    "\n",
    "    step = 0\n",
    "    step_best = step\n",
    "    \n",
    "    loop_length = 100000\n",
    "    loop_step = 0\n",
    "    loops_done = 0\n",
    "    start_compute = datetime.datetime.now()\n",
    "    for i in range(num_steps):\n",
    "        if num_problems_best == 0:\n",
    "            break\n",
    "        \n",
    "        edge_idx = np.random.randint(0,num_edges)\n",
    "        color_delta = np.random.randint(1,num_colors)\n",
    "        edge_color_old = coloring_cpu[edge_idx]\n",
    "        #edge_color_new = (edge_color_old + color_Deltas[i]) % num_colors\n",
    "        edge_color_new = (edge_color_old + color_delta) % num_colors\n",
    "        coloring_cpu[edge_idx] = edge_color_new\n",
    "        coloring_gpu.set(coloring_cpu)\n",
    "\n",
    "#         The code below check the pandas and cuda versions against each other.\n",
    "#         It is commented out by default because it slows things down.\n",
    "#         If you want to use it, you also need to uncomment several lines above to activate the pandas algorithm.\n",
    "\n",
    "#         num_problems_proposed, Problems_proposed_pandas = find_problems_pandas(coloring_cpu)#, printout=True)\n",
    "#         num_problems_proposed, Problems_proposed_cuda = find_problems_cuda(coloring_gpu, get_from_gpu=True, printout=False)\n",
    "#         if np.all(Problems_proposed_pandas == Problems_proposed_cuda) == True:\n",
    "#             print(\"Pandas and Cuda agree!!\")\n",
    "#         else:\n",
    "#             raise Exception(\"Pandas and Cuda disagree :()\")\n",
    "            \n",
    "        num_problems_proposed = find_problems_cuda(coloring_gpu, coloring_cpu,get_from_gpu=True, printout=False)\n",
    "        num_problems_diff = num_problems_current - num_problems_proposed\n",
    "        if num_problems_diff >= 0:\n",
    "             #print(\"Proposed is better.  Accepting.\")            \n",
    "            num_problems_current = num_problems_proposed\n",
    "            #Problems_current = Problems_proposed.copy()\n",
    "            if num_problems_proposed < num_problems_best:\n",
    "                step_best = step\n",
    "                coloring_best = coloring_cpu.copy()\n",
    "                num_problems_best = num_problems_proposed\n",
    "                #Problems_best = Problems_proposed.copy()\n",
    "                print_status()\n",
    "        else:            \n",
    "            accept = np.exp(beta * num_problems_diff)            \n",
    "            r = np.random.random()\n",
    "            #print(\"Proposed is worse.  But I will accept it anyway if I draw a number less than %.3f.  I drew %.3f.\" % (accept,r))            \n",
    "            if r <= accept:            \n",
    "                #print(\"So I accept the move even though it is worse.\")                \n",
    "                num_problems_current = num_problems_proposed\n",
    "                #Problems_current = Problems_proposed.copy()\n",
    "            else:                \n",
    "                #print(\"So I reject.\")\n",
    "                coloring_cpu[edge_idx] = edge_color_old\n",
    "        step += 1\n",
    "        loop_step += 1\n",
    "        if(loop_step >= loop_length):\n",
    "            loops_done += 1\n",
    "            loop_step = 0\n",
    "            print_status()\n",
    "            compute_time = (datetime.datetime.now() - start_compute).seconds\n",
    "            steps_done = loops_done*loop_length\n",
    "            rate = steps_done / compute_time\n",
    "            job_time = (num_steps-steps_done)/rate\n",
    "            m, s = divmod(job_time,60)\n",
    "            h, m = divmod(m,60)\n",
    "            d, h = divmod(h,24)\n",
    "            y, d = divmod(d,365)\n",
    "            print(\"At %.0f colorings/second, it'll take me %d years %d days %d hours %d minutes and %d seconds to complete the remaining steps.\"%\n",
    "                  (rate,y,d,h,m,s))\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"FINISHED!!\")\n",
    "    coloring_cpu = coloring_best.copy()\n",
    "    coloring_gpu.set(coloring_best)\n",
    "    num_problems_best  = find_problems_cuda(coloring_gpu, coloring_cpu,get_from_gpu=False, printout=False)\n",
    "    \n",
    "    print()\n",
    "    print_status()\n",
    "    final_coloring = pd.DataFrame()\n",
    "    final_coloring['edge'] = Edges\n",
    "    final_coloring['color'] = coloring_best[:num_edges]\n",
    "    display(final_coloring)\n",
    "    return final_coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "#blocks = gridDim.x = 471, cliques per block = threads per block = blockDim.x = 1150, edges per thread = 21\n",
      "(471, 1150, 21)\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuModuleGetFunction failed: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1cd4e0b0501a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmain_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRamsey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-1d597fb6d47f>\u001b[0m in \u001b[0;36mmain_random\u001b[0;34m(Ramsey, num_vertices, num_steps, beta)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#blocks = gridDim.x = %d, cliques per block = threads per block = blockDim.x = %d, edges per thread = %d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medges_per_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges_per_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"find_problems\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_problems_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoloring_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoloring_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_from_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m#Recall that red is defined to be the smallest of the colors so this code checks to see if there is less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/particle/anaconda2/lib/python2.7/site-packages/pycuda/compiler.pyc\u001b[0m in \u001b[0;36mget_function\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m: cuModuleGetFunction failed: named symbol not found"
     ]
    }
   ],
   "source": [
    "Ramsey = [3,7]\n",
    "num_vertices = 25\n",
    "num_steps = 50000\n",
    "\n",
    "#Ramsey = [3,3,4]\n",
    "#num_vertices = 30\n",
    "#num_steps = 1000000000\n",
    "\n",
    "beta = 4\n",
    "main_random(Ramsey, num_vertices, num_steps, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    #include <stdio.h>\n",
      "    __global__ void main_kernel(ushort *A)\n",
      "    {\n",
      "        if(threadIdx.x == 0)\n",
      "        {\n",
      "            printf(\"\\nAn example of using string replace to write THIS PART OF THE MESSAGE\\n\\n\");\n",
      "        }\n",
      "        \n",
      "        __shared__ uint A_shared[40];\n",
      "\n",
      "        if(threadIdx.x < 40)\n",
      "        {\n",
      "            A_shared[threadIdx.x] = A[threadIdx.x];\n",
      "            printf(\"I'm thread %d.  I see that A[%d] = %d\\n\",threadIdx.x,threadIdx.x,A_shared[threadIdx.x]);\n",
      "        }\n",
      "    }\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "kernel_code = \"\"\"\n",
    "    #include <stdio.h>\n",
    "    __global__ void main_kernel(ushort *A)\n",
    "    {\n",
    "        if(threadIdx.x == 0)\n",
    "        {\n",
    "            printf(\"\\\\nAn example of using string replace to write MACRO1\\\\n\\\\n\");\n",
    "        }\n",
    "        \n",
    "        __shared__ uint A_shared[A_LEN];\n",
    "\n",
    "        if(threadIdx.x < A_LEN)\n",
    "        {\n",
    "            A_shared[threadIdx.x] = A[threadIdx.x];\n",
    "            printf(\"I'm thread %d.  I see that A[%d] = %d\\\\n\",threadIdx.x,threadIdx.x,A_shared[threadIdx.x]);\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "A = np.arange(40)\n",
    "A_gpu = gpuarray.to_gpu(A.astype('uint16'))\n",
    "\n",
    "macros = {'MACRO1':'THIS PART OF THE MESSAGE'\n",
    "         ,'A_LEN':len(A)}\n",
    "\n",
    "for key, val in macros.items():\n",
    "    kernel_code = kernel_code.replace(str(key),str(val))\n",
    "print(kernel_code)\n",
    "\n",
    "mod = SourceModule(kernel_code);\n",
    "main = mod.get_function(\"main_kernel\")\n",
    "\n",
    "t = len(A)+10\n",
    "#Note that the last 10 will not print anything\n",
    "blockDims = (t,1,1)\n",
    "gridDims = (1,1,1)\n",
    "\n",
    "print(main(A_gpu, block=blockDims, grid=gridDims, shared=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
