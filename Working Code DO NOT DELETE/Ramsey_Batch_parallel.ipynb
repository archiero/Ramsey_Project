{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals for this update:\n",
    "1. Batches running evenly and do every batch, every search\n",
    "1. Batches be as even as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FYI for this and all future updates:\n",
    "I'm going to keeping the most recent working code as the bottom main_random and the in-progress version as the top one. This is to have it so I can easily see the most previous working model and to allow to incrementally change it without actually losing a working version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVIDIA DOC:\n",
    "http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#maximize-instruction-throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMITS FOR THE DATA TYPES:\n",
    "\n",
    "int8 \tByte (-128 to 127)\n",
    "\n",
    "int16 \tInteger (-32768 to 32767)\n",
    "\n",
    "int32 \tInteger (-2147483648 to 2147483647)\n",
    "\n",
    "int64 \tInteger (-9223372036854775808 to 9223372036854775807)\n",
    "\n",
    "uint8 \tUnsigned integer (0 to 255)\n",
    "\n",
    "uint16 \tUnsigned integer (0 to 65535)\n",
    "\n",
    "uint32 \tUnsigned integer (0 to 4294967295)\n",
    "\n",
    "uint64 \tUnsigned integer (0 to 18446744073709551615)\n",
    "\n",
    "CONVERSION USING NUMPY:\n",
    "\n",
    "(unsigned) char = numpy.(u)int8\n",
    "\n",
    "(unsigned) short = numpy.(u)int16\n",
    "\n",
    "(unsigned) int = numpy.(u)int32\n",
    "\n",
    "(unsigned) long = numpy.(u)int64 (only 64-bit)\n",
    "\n",
    "floats = numpy.float32\n",
    "\n",
    "double = numpy.float64\n",
    "\n",
    "all pointers ( e.g int *, float ***, anything at all) should be numpy.intp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from setup import *\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from collections import Counter\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "\n",
    "def main_random(Ramsey, num_vertices, num_steps, beta=2):\n",
    "    start_time = datetime.datetime.now()\n",
    "    print()\n",
    "    \n",
    "    def choose(n,k):\n",
    "        return int(math.factorial(n)/math.factorial(k)/math.factorial(n-k))\n",
    "    def min_red_edges(Ramsey, num_vertices):\n",
    "        sorted_Ramsey = np.sort(Ramsey)\n",
    "        k = sorted_Ramsey[1]\n",
    "        if len(sorted_Ramsey) != 2 or sorted_Ramsey[0] != 3:\n",
    "            return(0)\n",
    "        elif num_vertices <=2*k:\n",
    "            return(num_vertices-k)\n",
    "        elif num_vertices <= 5*k/2:\n",
    "            return(3*num_vertices - 5*k)\n",
    "        else:\n",
    "            return(5*num_vertices - 10*k)\n",
    "    min_red = min_red_edges(Ramsey, num_vertices)\n",
    "    num_colors = np.int(len(Ramsey))\n",
    "    Colors = np.arange(num_colors).astype(\"int\")\n",
    "    Vertices = np.arange(num_vertices).astype(\"int\")\n",
    "    Edges = list(it.combinations(Vertices,2))\n",
    "    #reverse lookup for edges below.  Eg if slot 3 above contains edge (2,5), the the dict below has entry (2,5):3\n",
    "    Edges_idx = dict((edge, idx) for idx,edge in enumerate(Edges)) \n",
    "    num_edges = len(Edges)\n",
    "    max_bytes = 4.2*10**9\n",
    "    #This is based off of the max global memory found in Lannister. It is just under 4.3 gigs. So I'm only allowing \n",
    "    #4.2 gigs of memory to used up with edges of cliques to check\n",
    "    \n",
    "    threads_per_block = 1024\n",
    "    vertices_per_clique = Ramsey\n",
    "    bytes_per_edge = 4\n",
    "    edges_per_clique = np.array([choose(v,2) for v in vertices_per_clique])\n",
    "    bytes_per_clique = np.array(edges_per_clique*bytes_per_edge) #uint32's take up 4 bytes.\n",
    "    cliques_per_color = np.asarray([choose(num_vertices,v) for v in vertices_per_clique])\n",
    "    bytes_per_color = np.asarray(bytes_per_clique*cliques_per_color)\n",
    "    #blocks_per_color = np.ceil(cliques_per_color / threads_per_block).astype('uint32')\n",
    "    #num_blocks = blocks_per_color.sum()\n",
    "    total_bytes = bytes_per_color.sum()\n",
    "    num_batches = np.int(2)#np.ceil(total_bytes/(max_bytes))#I'm not positive about this calculation. I'm going to \n",
    "    #double check it soon to make sure that Marvin can handle it.\n",
    "    \n",
    "    #These *_per_batch arrays are just the same as the corresponding *_per_color arrays but cut down to the right \n",
    "    #size. I.e. they are still indexed by color\n",
    "    cliques_per_batch = np.ceil(cliques_per_color/num_batches).astype(\"uint32\")\n",
    "    blocks_per_batch = np.ceil(cliques_per_batch/threads_per_block).astype(\"uint32\")\n",
    "    cliques_per_block = np.ceil(cliques_per_batch / blocks_per_batch).astype('uint32')\n",
    "    num_blocks_batch = blocks_per_batch.sum()\n",
    "    \n",
    "    block_color = np.repeat(Colors,blocks_per_batch).astype('uint32')#.astype('uint8')#\n",
    "    block_num_cliques = np.repeat(cliques_per_block,blocks_per_batch).astype('uint32')\n",
    "    block_edges_per_clique = np.repeat(edges_per_clique,blocks_per_batch).astype('uint32')#.astype('uint8')#\n",
    "    \n",
    "    assign_Blocks_to_Cliques = np.full([num_blocks_batch,cliques_per_block.max(),edges_per_clique.max()],\n",
    "                                       fill_value=num_colors, dtype='uint32')#dtype = \"uint8\")\n",
    "    \n",
    "    def assign_batches(batch_num):\n",
    "        next_open_block = 0    \n",
    "        next_open_thread = np.zeros(num_blocks_batch,dtype='int')\n",
    "        for color, clique_size in enumerate(Ramsey):        \n",
    "            num_cliques = cliques_per_batch[color]\n",
    "            #This starts out at the batch number and then returns every num_batch cliques. So, if we're on batch 2 of\n",
    "            #three it will return the second, fifth, eighth and etc batches. This makes sure that the batches are as\n",
    "            #close as possible with respect to number of cliques and size of those cliques\n",
    "            Cliques = it.combinations(Vertices,clique_size)\n",
    "            Batch_Cliques = it.islice(Cliques, batch_num, None, num_batches)\n",
    "            #Makes the vector [0,1,2,...,num_threads-1,0,1,2,...,num_threads-1,....] of length num_cliques        \n",
    "            assign_Cliques_to_Blocks = np.arange(cliques_per_batch[color]) % blocks_per_batch[color]\n",
    "            np.random.shuffle(assign_Cliques_to_Blocks)\n",
    "            #Starts at next open block\n",
    "            assign_Cliques_to_Blocks += next_open_block\n",
    "            for clique_Vertices, block in zip(Cliques,assign_Cliques_to_Blocks):\n",
    "                #Gets the list of edges in this clique\n",
    "                clique_Edges = list(it.combinations(clique_Vertices,2))\n",
    "                #Converts it to edge_idx\n",
    "                clique_Edges_idx = [Edges_idx[edge] for edge in clique_Edges]\n",
    "                #print(clique_Edges_idx)\n",
    "                #Writes it to the correct thread and next open slot on that thread\n",
    "                assign_Blocks_to_Cliques[block,next_open_thread[block],:edges_per_clique[color]] = clique_Edges_idx\n",
    "                next_open_thread[block] += 1\n",
    "            next_open_block += blocks_per_batch[color]\n",
    "        return(np.array(assign_Blocks_to_Cliques).astype(\"uint32\"))\n",
    "    #All of the arrays that we are going to need later:        \n",
    "    block_edges_per_clique_gpu = gpuarray.to_gpu_async(block_edges_per_clique)\n",
    "    block_color_gpu = gpuarray.to_gpu_async(block_color)\n",
    "    #This is the kernel call saved as a string literal which allows us to use regex to do stuff like dynamically allocate\n",
    "    #shared arrays.\n",
    "    kernel_code =\"\"\"\n",
    "   #include <stdio.h>\n",
    "   __global__ void find_problems(int *block_color, int *edges_per_clique, int *edges, int *coloring, int *Problems, int edges_per_thread)\n",
    "    {\n",
    "        __shared__ int shared_coloring[shared_size];\n",
    "        int color = block_color[blockIdx.x];\n",
    "        int clique_idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "        if(threadIdx.x < shared_size)\n",
    "        {\n",
    "            shared_coloring[threadIdx.x] = coloring[threadIdx.x];\n",
    "        }\n",
    "        int start = clique_idx*edges_per_thread;\n",
    "        int end = start + edges_per_clique[blockIdx.x];\n",
    "        int e = start;\n",
    "        while((e < end) && (shared_coloring[edges[e]] == color))\n",
    "        {  \n",
    "            e++;\n",
    "        }\n",
    "        //Problems[clique_idx] = (e >= end) ? 1 : 0;\n",
    "        if(e>=end)\n",
    "        {\n",
    "            atomicAdd(Problems, 1);\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    regex_fixing_dictionary = {\"shared_size\":num_edges}\n",
    "    for key,value in regex_fixing_dictionary.items():\n",
    "        kernel_code = kernel_code.replace(str(key), str(value))\n",
    "    mod = SourceModule(kernel_code);\n",
    "    func = mod.get_function(\"find_problems\")\n",
    "    \n",
    "    G, B, edges_per_thread = assign_Blocks_to_Cliques.shape\n",
    "    edges_per_thread = np.uint32(edges_per_thread)\n",
    "    print(\"#blocks = gridDim.x = %d, cliques per block = threads per block = blockDim.x = %d, edges per thread = %d\"%(G,B,edges_per_thread))\n",
    "    print(G, B, edges_per_thread)\n",
    "    #This creates a vector of zeros with length equal to the number of threads in a block. \n",
    "    no_prob_bob = np.zeros(1).astype(\"uint32\")\n",
    "    def find_problems_cuda(coloring_gpu, printout=False):#, get_from_gpu=False):\n",
    "        #This sends down one Problem vector the size of no_prob_bob. Then, if a thread with a threadIdx.x == 7, it goes\n",
    "        #to Problems[7-1] and increments it by one. \n",
    "        Problems_gpu = gpuarray.to_gpu(no_prob_bob)\n",
    "        for batch in range(num_batches):\n",
    "            batch_num = batch\n",
    "            assign_Blocks_to_Cliques = assign_batches(batch_num)\n",
    "            assign_Blocks_to_Cliques_gpu = gpuarray.to_gpu_async(assign_Blocks_to_Cliques)\n",
    "            func(block_color_gpu, block_edges_per_clique_gpu, assign_Blocks_to_Cliques_gpu, coloring_gpu, Problems_gpu, edges_per_thread, block=(B,1,1), grid=(G,1), shared=0)\n",
    "            #Problems = Problems_gpu.get()\n",
    "            #problems += np.sum(Problems)\n",
    "        if printout == True:\n",
    "            print_problems(problems)\n",
    "        return Problems_gpu.get().sum().astype(\"int32\")\n",
    "\n",
    "    def print_problems(Problems):        \n",
    "        Z = pd.DataFrame(Problems.astype('uint32'))\n",
    "        Z.insert(0,'problems',Z.sum(axis=1))\n",
    "        Z.insert(0,'color',block_color)\n",
    "        Z = Z.T\n",
    "        problem_idx = np.any(Z,axis=-1)\n",
    "        problem_idx[:2] = True\n",
    "        display(Z.ix[problem_idx,:])\n",
    "\n",
    "    def print_status():\n",
    "        now = datetime.datetime.now()\n",
    "        elapsed = now - start_time\n",
    "        print(\"%d steps done in %s.  Best coloring so far was step %d with %d problems.  Time now %s.\"\n",
    "                   %(step,str(elapsed).split('.')[0],step_best,num_problems_best,str(now).split('.')[0]))\n",
    "\n",
    "    \n",
    "    #Initialize the Markov chain\n",
    "    coloring_cpu = np.random.choice(Colors, size=num_edges+1, replace=True).astype('uint32')\n",
    "    coloring_cpu[num_edges] = num_colors\n",
    "    #Recall this last slot holds is a placeholder to handle \"extra\" slots.  \n",
    "    coloring_best = coloring_cpu.copy()\n",
    "    coloring_gpu = gpuarray.to_gpu_async(coloring_cpu.copy())\n",
    "    \n",
    "    #Problems_current = np.zeros(assign_Blocks_to_Cliques.shape[:-1]).astype('uint32')    \n",
    "    #Problems_gpu = gpuarray.GPUArray(assign_Blocks_to_Cliques.shape[:-1],dtype='uint32')\n",
    "    #HERE\n",
    "    num_problems_current = find_problems_cuda(coloring_gpu)\n",
    "    num_problems_proposed = 0\n",
    "    num_problems_best = num_problems_current\n",
    "\n",
    "    step = 0\n",
    "    step_best = step\n",
    "    loop_length = 100000\n",
    "    loop_step = 0\n",
    "    loops_done = 0\n",
    "    start_compute = datetime.datetime.now()\n",
    "    for step in range(num_steps):\n",
    "        edge_idx = np.random.randint(0,num_edges)\n",
    "        color_delta = np.random.randint(1,num_colors)\n",
    "        edge_color_old = coloring_cpu[edge_idx]\n",
    "        #edge_color_new = (edge_color_old + color_Deltas[i]) % num_colors\n",
    "        edge_color_new = (edge_color_old + color_delta) % num_colors\n",
    "        coloring_cpu[edge_idx] = edge_color_new\n",
    "        coloring_gpu.set(coloring_cpu)\n",
    "            \n",
    "        num_problems_proposed = find_problems_cuda(coloring_gpu)\n",
    "        num_problems_diff = num_problems_current - num_problems_proposed\n",
    "        if num_problems_diff >= 0:\n",
    "            print(\"Proposed is better.  Accepting.\", num_problems_proposed, num_problems_current,step, num_problems_diff)            \n",
    "            num_problems_current = num_problems_proposed\n",
    "            #Problems_current = Problems_proposed.copy()\n",
    "            if num_problems_proposed < num_problems_best:\n",
    "                print(step, num_problems_proposed, step_best, num_problems_best)\n",
    "                coloring_best = coloring_cpu.copy()\n",
    "                num_problems_best = num_problems_proposed\n",
    "                step_best = step\n",
    "                #Problems_best = Problems_proposed.copy()\n",
    "                #print_status()\n",
    "        else:            \n",
    "            accept = np.exp(beta * num_problems_diff)            \n",
    "            r = np.random.random()\n",
    "            #print(\"Proposed is worse.  But I will accept it anyway if I draw a number less than %.3f.  I drew %.3f.\" % (accept,r), num_problems_diff)            \n",
    "            if r <= accept:            \n",
    "                #print(\"So I accept the move even though it is worse.\")                \n",
    "                num_problems_current = num_problems_proposed\n",
    "            else:                \n",
    "                #print(\"So I reject.\")\n",
    "                coloring_cpu[edge_idx] = edge_color_old\n",
    "        step += 1\n",
    "        loop_step += 1\n",
    "        if(loop_step >= loop_length):\n",
    "            loops_done += 1\n",
    "            loop_step = 0\n",
    "            print_status()\n",
    "            compute_time = (datetime.datetime.now() - start_compute).seconds\n",
    "            steps_done = loops_done*loop_length\n",
    "            rate = steps_done / compute_time\n",
    "            job_time = (num_steps-steps_done)/rate\n",
    "            m, s = divmod(job_time,60)\n",
    "            h, m = divmod(m,60)\n",
    "            d, h = divmod(h,24)\n",
    "            y, d = divmod(d,365)\n",
    "            print(\"At %.0f colorings/second, it'll take me %d years %d days %d hours %d minutes and %d seconds to complete the remaining steps.\"%\n",
    "                  (rate,y,d,h,m,s))    \n",
    "\n",
    "    print(\"FINISHED!!\")\n",
    "    coloring_cpu = coloring_best.copy()\n",
    "    coloring_gpu.set(coloring_best)\n",
    "    num_problems_proposed = find_problems_cuda(coloring_gpu)\n",
    "    if(num_problems_proposed != num_problems_best):\n",
    "        print(\"Something isn't saving right\")\n",
    "    #print()\n",
    "    print_status()\n",
    "    final_coloring = pd.DataFrame()\n",
    "    final_coloring['edge'] = Edges\n",
    "    final_coloring['color'] = coloring_best[:num_edges]\n",
    "    display(final_coloring)\n",
    "    return final_coloring, num_problems_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ramsey = [4,6]\n",
    "num_vertices = 35\n",
    "\n",
    "num_steps = (5*10**1)\n",
    "import datetime \n",
    "#Ramsey = [3,3,4]\n",
    "#num_vertices = 30\n",
    "#num_steps = 1000000000\n",
    "\n",
    "beta = 1\n",
    "bill = main_random(Ramsey, num_vertices, num_steps, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT TOUCH WHAT IS BELOW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from setup import *\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import random\n",
    "\n",
    "def main_random(Ramsey, num_vertices, num_steps, beta=2):\n",
    "    start_time = datetime.datetime.now()\n",
    "    print()\n",
    "\n",
    "    def choose(n,k):\n",
    "        return int(math.factorial(n)/math.factorial(k)/math.factorial(n-k))\n",
    "    #The theory for this function comes from the Lesser Paper. Theorem 7 there provides very useful lower-bounds \n",
    "    #for the number of red edges found \n",
    "    def min_red_edges(Ramsey, num_vertices):\n",
    "        sorted_Ramsey = np.sort(Ramsey)\n",
    "        k = sorted_Ramsey[1]\n",
    "        if len(sorted_Ramsey) != 2 or sorted_Ramsey[0] != 3:\n",
    "            return(0)\n",
    "        elif num_vertices <=2*k:\n",
    "            return(num_vertices-k)\n",
    "        elif num_vertices <= 5*k/2:\n",
    "            return(3*num_vertices - 5*k)\n",
    "        else:\n",
    "            return(5*num_vertices - 10*k)\n",
    "    min_red = min_red_edges(Ramsey, num_vertices)\n",
    "    num_colors = len(Ramsey)\n",
    "    Colors = np.arange(num_colors)\n",
    "    Vertices = np.arange(num_vertices)\n",
    "    Edges = list(it.combinations(Vertices,2))\n",
    "    #reverse lookup for edges below.  Eg if slot 3 above contains edge (2,5), the the dict below has entry (2,5):3\n",
    "    Edges_idx = dict((edge, idx) for idx,edge in enumerate(Edges)) \n",
    "    num_edges = len(Edges)\n",
    "\n",
    "    threads_per_block = 1024\n",
    "    vertices_per_clique = Ramsey\n",
    "    edges_per_clique = np.array([choose(v,2) for v in vertices_per_clique])\n",
    "    cliques_per_color = np.asarray([choose(num_vertices,v) for v in vertices_per_clique])\n",
    "    blocks_per_color = np.ceil(cliques_per_color / threads_per_block).astype('uint32')\n",
    "    num_blocks = blocks_per_color.sum()\n",
    "    cliques_per_block = np.ceil(cliques_per_color / blocks_per_color).astype('uint32')\n",
    "    #The objects below tells each block which color and how many cliques/edges it will monitor.\n",
    "    #Note each vector is repetitive.  If color 0 gets 7 blocks, the first 7 entries will be the same\n",
    "    block_color = np.repeat(Colors,blocks_per_color).astype('uint32')\n",
    "    block_num_cliques = np.repeat(cliques_per_block,blocks_per_color).astype('uint32')\n",
    "    block_edges_per_clique = np.repeat(edges_per_clique,blocks_per_color).astype('uint32')\n",
    "    \n",
    "    #The object below assigns each block to a list of cliques.  For simplicity while\n",
    "    #we construct a single matrix with a lot of unused entries.\n",
    "    #For example, edges_per_clique is different for blocks monitoring different colors.\n",
    "    #We could make a more complex structure that handles this (see old stable version)\n",
    "    #but that makes it harder to pass to the GPU.  Instead, we simply fill all \"invalid\"\n",
    "    #unused entries with the placeholder \"num_edges\", which is 1 more the the largest\n",
    "    #legal edge_idx (because Python indexes [0,1,2,...,num_edges-1]).\n",
    "    #When we color later, we color these slots with the placeholder num_colors.\n",
    "    assign_Blocks_to_Cliques = np.full([num_blocks,cliques_per_block.max(),edges_per_clique.max()],\n",
    "                                       fill_value=num_edges, dtype='uint32')\n",
    "\n",
    "    #Counters that that tracks the next open block and thread on each block\n",
    "    next_open_block = 0    \n",
    "    next_open_thread = np.zeros(num_blocks,dtype='int')\n",
    "    for color, clique_size in enumerate(Ramsey):\n",
    "        #Creates a generator to produce all cliques (the list of vertices).\n",
    "        Cliques = it.combinations(Vertices,clique_size)\n",
    "\n",
    "        #Makes the vector [0,1,2,...,num_blocks-1,0,1,2,...,num_blocks-1,....] of length num_cliques\n",
    "        assign_Cliques_to_Blocks = np.arange(cliques_per_color[color]) % blocks_per_color[color]\n",
    "        #randomizes assignment, but maintains clique counts\n",
    "        np.random.shuffle(assign_Cliques_to_Blocks)\n",
    "        #Starts at next open block\n",
    "        assign_Cliques_to_Blocks += next_open_block\n",
    "        \n",
    "        for clique_Vertices, block in zip(Cliques,assign_Cliques_to_Blocks):\n",
    "            #Gets the list of edges in this clique\n",
    "            clique_Edges = list(it.combinations(clique_Vertices,2))\n",
    "            #Converts it to edge_idx\n",
    "            clique_Edges_idx = [Edges_idx[edge] for edge in clique_Edges]\n",
    "            #Writes it to the correct block and next open thread on that block\n",
    "            assign_Blocks_to_Cliques[block,next_open_thread[block],:edges_per_clique[color]] = clique_Edges_idx            \n",
    "            next_open_thread[block] += 1\n",
    "        next_open_block += blocks_per_color[color]\n",
    "\n",
    "#     print(\"Ramsey\");print(Ramsey);print(\"edges per clique\");print(edges_per_clique);print(\"cliques per color\");print(cliques_per_color);print(\"blocks per color\");print(blocks_per_color);print(\"cliques per block\");print(cliques_per_block)\n",
    "#     for (idx, block)  in enumerate(assign_Blocks_to_Cliques):\n",
    "#         print()\n",
    "#         print(\"block = \"+str(idx));\n",
    "#         print(\"color = \"+str(block_color[idx]));\n",
    "#         print(\"num_cliques = \"+str(block_num_cliques[idx]));\n",
    "#         print(\"edges per clique = \"+str(block_edges_per_clique[idx]));\n",
    "#         print(block.shape, block.dtype);\n",
    "#         display(block);\n",
    "#         display(compare)\n",
    "  \n",
    "    \n",
    "    #Code below sets up the GPU checker\n",
    "    block_color_gpu = gpuarray.to_gpu(block_color)\n",
    "    #block_num_cliques = gpuarray.to_gpu(block_num_cliques)\n",
    "    block_edges_per_clique_gpu = gpuarray.to_gpu(block_edges_per_clique)\n",
    "    assign_Blocks_to_Cliques_gpu = gpuarray.to_gpu(assign_Blocks_to_Cliques)    \n",
    "\n",
    "    #mod = SourceModule(\"\"\"\n",
    "    #__global__ void find_problems(int *block_color, int *edges_per_clique, int *edges, int *coloring, int *Problems, int edges_per_thread)\n",
    "    #{\n",
    "    #    int color = block_color[blockIdx.x];\n",
    "    #    int clique_idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "    #    int start = clique_idx*edges_per_thread;\n",
    "    #    int end = start + edges_per_clique[blockIdx.x];\n",
    "    #    int e = start;\n",
    "    #    while((e < end) && (coloring[edges[e]] == color)){\n",
    "    #        e++;\n",
    "    #    }\n",
    "    #    Problems[clique_idx] = (e >= end) ? 1 : 0;\n",
    "    #}\n",
    "    #\"\"\")\n",
    "    kernel_code =\"\"\"\n",
    "    #include <stdio.h>\n",
    "    __global__ void find_problems(int *block_color, int *edges_per_clique, int *edges, int *coloring, int *Problems, int edges_per_thread, int cliques)\n",
    "    {\n",
    "        __shared__ int shared_coloring[shared_size];\n",
    "        int color = block_color[blockIdx.x];\n",
    "        int clique_idx = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "        if(threadIdx.x < shared_size)\n",
    "        {\n",
    "            shared_coloring[threadIdx.x] = coloring[threadIdx.x];\n",
    "        }\n",
    "        if(clique_idx < cliques)\n",
    "        {\n",
    "            //This weird way of starting and stopping allows us to traverse the 3D-array of assign_Blocks_to_Cliques easily\n",
    "            int start = clique_idx*edges_per_thread;\n",
    "            int end = start + edges_per_clique[blockIdx.x];\n",
    "            int e = start;\n",
    "            while((e < end) && (shared_coloring[edges[e]] == color))\n",
    "            {\n",
    "                e++;\n",
    "            }\n",
    "            //Problems[clique_idx] = 0;\n",
    "            //(e >= end) ? atomicAdd(Problems[clique_idx],int 1) : atomicAdd(Problems[clique_idx],int 0);\n",
    "            Problems[clique_idx] = (e >= end) ? 1 : 0;\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    regex_fixing_dictionary = {\"shared_size\":(num_edges+1)}\n",
    "\n",
    "    for key, val in regex_fixing_dictionary.items():\n",
    "        kernel_code = kernel_code.replace(str(key),str(val))\n",
    "    mod = SourceModule(kernel_code)\n",
    "    G, B, edges_per_thread = assign_Blocks_to_Cliques_gpu.shape\n",
    "    edges_per_thread = np.uint32(edges_per_thread)\n",
    "    print(\"#blocks = gridDim.x = %d, cliques per block = threads per block = blockDim.x = %d, edges per thread = %d\"%(G,B,edges_per_thread))\n",
    "    func = mod.get_function(\"find_problems\")\n",
    "    def find_problems_cuda(coloring_gpu, printout=False, get_from_gpu=False):\n",
    "        func(block_color_gpu, block_edges_per_clique_gpu, assign_Blocks_to_Cliques_gpu, coloring_gpu, Problems_gpu, edges_per_thread, np.uint32(cliques_per_color.sum()), block=(B,1,1), grid=(G,1), shared=0)\n",
    "        if printout == True:\n",
    "            get_from_gpu = True\n",
    "        if get_from_gpu == True:\n",
    "            #print(\"getting from gpu\")\n",
    "            Problems_cpu = Problems_gpu.get()\n",
    "            #cuda.memcpy_dtoh_async(Problems_gpu, Problems_cpu)\n",
    "            if printout == True:\n",
    "                print_problems(Problems_cpu)\n",
    "        else:\n",
    "            Problems_cpu = []\n",
    "        return gpuarray.sum(Problems_gpu).get().astype('uint32'), Problems_cpu\n",
    "    \n",
    "    #The code below setups the serial version of this algorithm in pandas on the CPU.\n",
    "    #It is much slower than the gpu version, but can be used in the absence of a GPU\n",
    "    #and to verify that the algorithms give the same answers.\n",
    "    #We msut create the \"comparison\" array.  This is a bit complicated.\n",
    "    #We will discuss 2 arrays: compare and the coloring array.\n",
    "    #First, recall that num_colors is one larger than the biggest legal color since\n",
    "    #Python indexes [0,1,...,num_colors-1]\n",
    "    #Now, fix a block and let c = block_color[block].\n",
    "    #Consider the [block, clique, edge] entry of compare.  It equals:\n",
    "    #c IF edge < num_edges_per_clique for that block\n",
    "    #num_colors IF clique >= num_edges_per_clique for that block\n",
    "    #Why?  In general there are extra rows and columns not associated to a valid edge.\n",
    "    #When we color the graph later, they are filled with num_colors.\n",
    "    #We do NOT want the \"space fillers\" to affect problem count.\n",
    "    #In the extra rows, we see [c,c,...,c,num_colors,num_colors,...,num_colors] in compare\n",
    "    #But in the coloring array, all entries will equal num_colors.\n",
    "    #Thus, it is NOT counted as a problem because the first several slots disagree.\n",
    "    #Thus, these extra rows can NEVER counts as problems cliques, as desired.\n",
    "    #Now, consider the extra columns.  All entries will equal num_colors.  This is true\n",
    "    #for BOTH compare AND the coloring array.  Thus, a row counts as a problem\n",
    "    #if and only if the first num_edges_per_clique \"valid\" entries also match.\n",
    "    #Thus the extra columns do NOT alter the \"problem status\" for valid rows, as desired.\n",
    "\n",
    "    compare = np.full_like(assign_Blocks_to_Cliques, fill_value=num_colors)\n",
    "    print(assign_Blocks_to_Cliques.shape)\n",
    "    for block in range(num_blocks):\n",
    "        compare[block,:,:block_edges_per_clique[block]] = block_color[block]\n",
    "    \n",
    "    def find_problems_pandas(coloring, printout=False):\n",
    "        X = coloring[assign_Blocks_to_Cliques]\n",
    "        Y = (X == compare)\n",
    "        Problems = np.all(Y,axis=-1)\n",
    "        if printout == True:\n",
    "            print_problems(Problems)\n",
    "        return Problems.sum().astype('int'), Problems\n",
    "\n",
    "    def print_problems(Problems):        \n",
    "        Z = pd.DataFrame(Problems.astype('uint32'))\n",
    "        Z.insert(0,'problems',Z.sum(axis=1))\n",
    "        Z.insert(0,'color',block_color)\n",
    "        Z = Z.T\n",
    "        problem_idx = np.any(Z,axis=-1)\n",
    "        problem_idx[:2] = True\n",
    "        display(Z.ix[problem_idx,:])\n",
    "\n",
    "    def print_status():\n",
    "        now = datetime.datetime.now()\n",
    "        elapsed = now - start_time\n",
    "        print(\"%d steps done in %s.  Best coloring so far was step %d with %d problems.  Time now %s.\"\n",
    "                   %(step,str(elapsed).split('.')[0],step_best,num_problems_best,str(now).split('.')[0]))\n",
    "    def increase_red_edges():\n",
    "        while(list(coloring_cpu).count(red)<min_red):\n",
    "            idx = [i for i in range(len(coloring_cpu)) if coloring_cpu[i]!=red]\n",
    "            coloring_cpu[random.choice(idx)] = red\n",
    "    #Initialize the Markov chain\n",
    "    coloring_cpu = np.random.choice(Colors, size=num_edges+1, replace=True).astype('uint32')\n",
    "    coloring_cpu[num_edges] = num_colors\n",
    "    #Recall this last slot holds is a placeholder to handlge \"extra\" slots.  See discussion\n",
    "    #of serial pandas algorithm above.\n",
    "    coloring_best = coloring_cpu.copy()\n",
    "    coloring_gpu = gpuarray.to_gpu(coloring_cpu.copy())\n",
    "    \n",
    "    #Problems_current = np.zeros(assign_Blocks_to_Cliques.shape[:-1]).astype('uint32')    \n",
    "    #Problems_gpu = gpuarray.GPUArray(assign_Blocks_to_Cliques.shape[:-1],dtype='uint32')\n",
    "    Problems_gpu = gpuarray.to_gpu(np.zeros(assign_Blocks_to_Cliques.shape[:-1]).astype(\"uint32\"))\n",
    "\n",
    "    #num_problems_current, Problems_current = find_problems_pandas(coloring_cpu, printout=False)\n",
    "    #num_problems_current, Problems_current = find_problems_cuda(coloring_gpu, get_from_gpu=True, printout=False)\n",
    "    num_problems_current, _ = find_problems_cuda(coloring_gpu, get_from_gpu=False, printout=False)    \n",
    "    num_problems_proposed = num_problems_current    \n",
    "    num_problems_best = num_problems_current\n",
    "    #Problems_proposed = Problems_current.copy()\n",
    "    #Problems_best = Problems_current.copy()\n",
    "    red = min(vertices_per_clique)\n",
    "    step = 0\n",
    "    step_best = step\n",
    "    \n",
    "    loop_length = 100000\n",
    "    loop_step = 0\n",
    "    loops_done = 0\n",
    "    start_compute = datetime.datetime.now()\n",
    "    for i in range(num_steps):\n",
    "        #if num_problems_best == 0:\n",
    "        #    break\n",
    "        \n",
    "        edge_idx = np.random.randint(0,num_edges)\n",
    "        color_delta = np.random.randint(1,num_colors)\n",
    "        edge_color_old = coloring_cpu[edge_idx]\n",
    "        #edge_color_new = (edge_color_old + color_Deltas[i]) % num_colors\n",
    "        edge_color_new = (edge_color_old + color_delta) % num_colors\n",
    "        coloring_cpu[edge_idx] = edge_color_new\n",
    "        if(list(coloring_cpu).count(red) < min_red):\n",
    "            increase_red_edges()    \n",
    "        coloring_gpu.set(coloring_cpu)\n",
    "\n",
    "#         The code below check the pandas and cuda versions against each other.\n",
    "#         It is commented out by default because it slows things down.\n",
    "#         If you want to use it, you also need to uncomment several lines above to activate the pandas algorithm.\n",
    "\n",
    "        num_problems_proposed, Problems_proposed_pandas = find_problems_pandas(coloring_cpu)#, printout=True)\n",
    "        num_problems_proposed, Problems_proposed_cuda = find_problems_cuda(coloring_gpu, get_from_gpu=True, printout=False)\n",
    "        if np.all(Problems_proposed_pandas == Problems_proposed_cuda) == True:\n",
    "            print(\"Pandas and Cuda agree!!\")\n",
    "        else:\n",
    "            raise Exception(\"Pandas and Cuda disagree :()\")\n",
    "            \n",
    "        num_problems_proposed, _ = find_problems_cuda(coloring_gpu, get_from_gpu=False, printout=False)\n",
    "        num_problems_diff = num_problems_current - num_problems_proposed\n",
    "        if num_problems_diff >= 0:\n",
    "             #print(\"Proposed is better.  Accepting.\")            \n",
    "            num_problems_current = num_problems_proposed\n",
    "            #Problems_current = Problems_proposed.copy()\n",
    "            if num_problems_proposed < num_problems_best:\n",
    "                step_best = step\n",
    "                coloring_best = coloring_cpu.copy()\n",
    "                num_problems_best = num_problems_proposed\n",
    "                #Problems_best = Problems_proposed.copy()\n",
    "                print_status()\n",
    "        else:            \n",
    "            accept = np.exp(beta * num_problems_diff)            \n",
    "            r = np.random.random()\n",
    "            #print(\"Proposed is worse.  But I will accept it anyway if I draw a number less than %.3f.  I drew %.3f.\" % (accept,r))            \n",
    "            if r <= accept:            \n",
    "                #print(\"So I accept the move even though it is worse.\")                \n",
    "                num_problems_current = num_problems_proposed\n",
    "                #Problems_current = Problems_proposed.copy()\n",
    "            else:                \n",
    "                #print(\"So I reject.\")\n",
    "                coloring_cpu[edge_idx] = edge_color_old\n",
    "        step += 1\n",
    "        loop_step += 1\n",
    "        if(loop_step >= loop_length):\n",
    "            loops_done += 1\n",
    "            loop_step = 0\n",
    "            print_status()\n",
    "            compute_time = (datetime.datetime.now() - start_compute).seconds\n",
    "            steps_done = loops_done*loop_length\n",
    "            rate = steps_done / compute_time\n",
    "            job_time = (num_steps-steps_done)/rate\n",
    "            m, s = divmod(job_time,60)\n",
    "            h, m = divmod(m,60)\n",
    "            d, h = divmod(h,24)\n",
    "            y, d = divmod(d,365)\n",
    "            print(\"At %.0f colorings/second, it'll take me %d years %d days %d hours %d minutes and %d seconds to complete the remaining steps.\"%\n",
    "                  (rate,y,d,h,m,s))\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"FINISHED!!\")\n",
    "    coloring_cpu = coloring_best.copy()\n",
    "    coloring_gpu.set(coloring_best)\n",
    "    num_problems_best, _   = find_problems_cuda(coloring_gpu, get_from_gpu=False, printout=False)\n",
    "    \n",
    "    print()\n",
    "    print_status()\n",
    "    final_coloring = pd.DataFrame()\n",
    "    final_coloring['edge'] = Edges\n",
    "    final_coloring['color'] = coloring_best[:num_edges]\n",
    "    display(final_coloring)\n",
    "    return final_coloring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOU MAY NOW EDIT CODE AGAIN. DO NOT TOUCH WHAT IS DIRECTLY ABOVE ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ramsey = [4,6]\n",
    "num_vertices = 35\n",
    "\n",
    "num_steps = 2*10**2\n",
    "import datetime \n",
    "#Ramsey = [3,3,4]\n",
    "#num_vertices = 30\n",
    "#num_steps = 1000000000\n",
    "\n",
    "beta = 1\n",
    "bill = main_random(Ramsey, num_vertices, num_steps, beta=beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
